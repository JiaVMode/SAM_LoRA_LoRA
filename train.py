#!/usr/bin/env python3
"""
AutoSAM 2D Training for Thymoma Segmentation
åŸºäº AutoSAM çš„è‡ªåŠ¨åˆ†å‰²è®­ç»ƒï¼Œæ— éœ€æ‰‹åŠ¨ prompt
"""

import os
import sys
import argparse
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader
from tqdm import tqdm
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from models.model_single import ModelEmb, MaskRefinement2D
from dataset.thymoma_dataset import get_thymoma_dataset_2d
from segment_anything import sam_model_registry
from segment_anything.utils.transforms import ResizeLongestSide


device = torch.device("cuda" if torch.cuda.is_available() else "cpu")


def norm_batch(x):
    """Normalize batch to [0, 1]"""
    bs = x.shape[0]
    Isize = x.shape[-1]
    min_value = x.view(bs, -1).min(dim=1)[0].view(bs, 1, 1, 1)
    max_value = x.view(bs, -1).max(dim=1)[0].view(bs, 1, 1, 1)
    x = (x - min_value) / (max_value - min_value + 1e-6)
    return x


def dice_loss(y_pred, y_true, smooth=1e-6):
    """Dice Loss (y_pred is logits)"""
    y_pred = y_pred.sigmoid().clamp(0, 1)
    y_true = y_true.clamp(0, 1)
    
    intersection = (y_pred * y_true).sum(dim=(2, 3))
    union = y_pred.sum(dim=(2, 3)) + y_true.sum(dim=(2, 3))
    
    dice = (2 * intersection + smooth) / (union + smooth)
    return 1 - dice.mean()


def calculate_dice(pred, target):
    """Calculate Dice coefficient"""
    pred = (pred > 0.5).float()
    target = (target > 0.5).float()
    
    intersection = (pred * target).sum()
    union = pred.sum() + target.sum()
    
    if union == 0:
        return 1.0
    return (2 * intersection / union).item()


def sam_forward(sam, image, dense_embeddings):
    """SAM forward pass with custom dense embeddings"""
    with torch.no_grad():
        # è·å–å›¾åƒ embedding
        image_embeddings = sam.image_encoder(image)
        
        # è·å–ç©ºçš„ sparse embeddings
        sparse_embeddings, _ = sam.prompt_encoder(
            points=None, boxes=None, masks=None
        )
    
    # ä½¿ç”¨è‡ªå®šä¹‰çš„ dense embeddings (æ¥è‡ª ModelEmb)
    low_res_masks, iou_predictions = sam.mask_decoder(
        image_embeddings=image_embeddings,
        image_pe=sam.prompt_encoder.get_dense_pe(),
        sparse_prompt_embeddings=sparse_embeddings,
        dense_prompt_embeddings=dense_embeddings,
        multimask_output=False,
    )
    
    return low_res_masks, iou_predictions


class AutoSAMTrainer:
    """AutoSAM è®­ç»ƒå™¨"""
    
    def __init__(self, args):
        self.args = args
        self.device = device
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path(args['output_dir'])
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ– SAM
        print(f"åŠ è½½ SAM: {args['sam_checkpoint']}")
        self.sam = sam_model_registry[args['model_type']](
            checkpoint=args['sam_checkpoint']
        )
        self.sam.to(device)
        self.sam.eval()  # SAM ä¿æŒå†»ç»“
        
        # å†»ç»“ SAM å‚æ•°
        for param in self.sam.parameters():
            param.requires_grad = False
        
        # åˆå§‹åŒ– ModelEmb (å¯è®­ç»ƒ)
        print("åˆå§‹åŒ– ModelEmb...")
        self.model = ModelEmb(args).to(device)
        
        # å¯é€‰çš„ mask ç»†åŒ–å±‚
        self.mask_refine = MaskRefinement2D(1, 1).to(device)
        
        # LoRA æ¨¡å¼
        self.use_lora = args.get('use_lora', False)
        if self.use_lora:
            from models.lora import apply_lora_to_model, get_lora_parameters
            lora_rank = int(args.get('lora_rank', 8))
            lora_alpha = float(args.get('lora_alpha', 16.0))
            
            print(f"[LoRA] å¯ç”¨ LoRA å¾®è°ƒæ¨¡å¼ (rank={lora_rank}, alpha={lora_alpha})")
            
            # å…ˆå†»ç»“æ‰€æœ‰å‚æ•°
            for param in self.model.parameters():
                param.requires_grad = False
            for param in self.mask_refine.parameters():
                param.requires_grad = False
            # SAM å·²ç»åœ¨ä¸Šé¢è¢«å†»ç»“äº†
            
            # åº”ç”¨ LoRA
            # 1. ModelEmb & MaskRefine (Conv2d å¯†é›†)
            self.model = apply_lora_to_model(self.model, rank=lora_rank, alpha=lora_alpha, apply_to_conv=True)
            self.mask_refine = apply_lora_to_model(self.mask_refine, rank=lora_rank, alpha=lora_alpha, apply_to_conv=True)
            
            # 2. SAM (Linear å¯†é›† - Attention)
            # æˆ‘ä»¬åªå¯¹ SAM çš„ Encoder å’Œ Mask Decoder åº”ç”¨ LoRAï¼ŒPrompt Encoder ä¿æŒå†»ç»“
            print("[LoRA] å¯¹ SAM åº”ç”¨ LoRA...")
            self.sam.image_encoder = apply_lora_to_model(self.sam.image_encoder, rank=lora_rank, alpha=lora_alpha, apply_to_conv=False)
            self.sam.mask_decoder = apply_lora_to_model(self.sam.mask_decoder, rank=lora_rank, alpha=lora_alpha, apply_to_conv=False)
            
            # æ”¶é›†æ‰€æœ‰ LoRA å‚æ•°
            trainable_params = (
                get_lora_parameters(self.model) + 
                get_lora_parameters(self.mask_refine) + 
                get_lora_parameters(self.sam.image_encoder) + 
                get_lora_parameters(self.sam.mask_decoder)
            )
            print(f"[LoRA] å¯è®­ç»ƒå‚æ•°æ€»æ•°: {sum(p.numel() for p in trainable_params):,}")
        else:
            # å…¨é‡å¾®è°ƒæ¨¡å¼
            trainable_params = list(self.model.parameters()) + list(self.mask_refine.parameters())
        
        # ä¼˜åŒ–å™¨
        self.optimizer = optim.AdamW(
            trainable_params,
            lr=float(args['learning_rate']),
            weight_decay=float(args['weight_decay']),
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer, T_max=int(args['epochs'])
        )
        
        # æŸå¤±å‡½æ•° - BCEWithLogitsLoss (AMP safe, ä¸ä½¿ç”¨ pos_weight ä»¥é¿å…ä¸ç¨³å®š)
        self.bce_loss = nn.BCEWithLogitsLoss()
        

        
        # AMP æ··åˆç²¾åº¦
        self.use_amp = args.get('use_amp', True)
        self.scaler = torch.cuda.amp.GradScaler(enabled=self.use_amp)
        if self.use_amp:
            print("å¯ç”¨ AMP æ··åˆç²¾åº¦è®­ç»ƒ")
        
        # SAM å˜æ¢
        self.sam_transform = ResizeLongestSide(self.sam.image_encoder.img_size)
        
        # åŠ è½½æ•°æ®
        print("åŠ è½½æ•°æ®...")
        self.train_dataset, self.val_dataset = get_thymoma_dataset_2d(args, self.sam_transform)
        
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=int(args['batch_size']),
            shuffle=True,
            num_workers=int(args['num_workers']),
            drop_last=True,
            pin_memory=True,
        )
        
        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=int(args.get('val_batch_size', args['batch_size'])),  # ä½¿ç”¨é…ç½®çš„ batch size
            shuffle=False,
            num_workers=int(args['num_workers']),
        )
        
        self.best_dice = 0
        
        # ç»Ÿè®¡å‚æ•°é‡
        total_params = sum(p.numel() for p in trainable_params if p.requires_grad)
        print(f"å¯è®­ç»ƒå‚æ•°: {total_params:,}")
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ª epoch"""
        self.model.train()
        self.mask_refine.train()
        
        losses = []
        dices = []
        
        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch}")
        
        for batch_idx, (images, masks, _, _) in enumerate(pbar):
            images = images.to(self.device)
            masks = masks.to(self.device).unsqueeze(1)  # (B, 1, H, W)
            
            # ModelEmb éœ€è¦è¾ƒå°çš„è¾“å…¥å°ºå¯¸
            Idim = int(self.args.get('Idim', 256))
            images_small = F.interpolate(images, (Idim, Idim), mode='bilinear', align_corners=True)
            
            # AMP æ··åˆç²¾åº¦
            with torch.cuda.amp.autocast(enabled=self.use_amp):
                # è·å– dense embeddings
                dense_embeddings = self.model(images_small)
                
                # SAM å‰å‘ä¼ æ’­
                low_res_masks, _ = sam_forward(self.sam, images, dense_embeddings)
                
                # å¯é€‰çš„ mask ç»†åŒ–
                refined_masks = self.mask_refine(low_res_masks)
                
                # è°ƒæ•´ GT å°ºå¯¸åŒ¹é…é¢„æµ‹
                masks_resized = F.interpolate(masks, refined_masks.shape[-2:], mode='nearest')
                
                # è®¡ç®—æŸå¤±
                loss_bce = self.bce_loss(refined_masks, masks_resized)
                loss_dice = dice_loss(refined_masks, masks_resized)
                # æé«˜ Dice Loss æƒé‡ï¼Œé™ä½ BCE æƒé‡ (èƒŒæ™¯å¤ªå¤š)
                loss = 0.5 * loss_bce + loss_dice
            
            # åå‘ä¼ æ’­ (ä½¿ç”¨ GradScaler)
            self.optimizer.zero_grad()
            self.scaler.scale(loss).backward()
            self.scaler.unscale_(self.optimizer)
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)
            self.scaler.step(self.optimizer)
            self.scaler.update()
            
            # è®¡ç®— Dice
            with torch.no_grad():
                pred_binary = (refined_masks.sigmoid() > 0.5).float()  # åº”ç”¨ sigmoid åé˜ˆå€¼åŒ–
                dice = calculate_dice(pred_binary, masks_resized)
                
                # è°ƒè¯•è¾“å‡º (æ¯ 100 ä¸ª batch)
                if batch_idx % 10 == 0:
                    pred_sum = pred_binary.sum().item()
                    gt_sum = masks_resized.sum().item()
                    pred_max = refined_masks.max().item()
                    pred_min = refined_masks.min().item()
                    tqdm.write(f"  [Debug] Pred sum: {pred_sum:.0f}, GT sum: {gt_sum:.0f}, Pred prob: [{pred_min:.2f}, {pred_max:.2f}]")
            
            losses.append(loss.item())
            dices.append(dice)
            
            pbar.set_postfix({
                'loss': f'{np.mean(losses[-50:]):.4f}',
                'dice': f'{np.mean(dices[-50:]):.4f}',
            })
        
        return np.mean(losses), np.mean(dices)
    
    @torch.no_grad()
    def validate(self, epoch):
        """éªŒè¯"""
        self.model.eval()
        self.mask_refine.eval()
        
        dices = []
        
        pbar = tqdm(self.val_loader, desc="Validation")
        
        for images, masks, _, _ in pbar:
            images = images.to(self.device)
            masks = masks.to(self.device).unsqueeze(1)
            
            Idim = int(self.args.get('Idim', 256))
            images_small = F.interpolate(images, (Idim, Idim), mode='bilinear', align_corners=True)
            
            dense_embeddings = self.model(images_small)
            low_res_masks, _ = sam_forward(self.sam, images, dense_embeddings)
            refined_masks = self.mask_refine(low_res_masks)
            
            masks_resized = F.interpolate(masks, refined_masks.shape[-2:], mode='nearest')
            
            pred_binary = (refined_masks.sigmoid() > 0.5).float()
            dice = calculate_dice(pred_binary, masks_resized)
            dices.append(dice)
            
            pbar.set_postfix({'dice': f'{np.mean(dices):.4f}'})
        
        return np.mean(dices)
    
    def save_checkpoint(self, epoch, dice, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'mask_refine_state_dict': self.mask_refine.state_dict(),
            # å¦‚æœç”¨äº† LoRAï¼Œä¹Ÿä¿å­˜ SAM çš„ LoRA æƒé‡
            'sam_lora_state_dict': self.sam.state_dict() if self.use_lora else None,
            'optimizer_state_dict': self.optimizer.state_dict(),
            'dice': dice,
            'args': self.args,
            'use_lora': self.use_lora,  # è®°å½•æ˜¯å¦ä½¿ç”¨ LoRA
        }
        
        # ä¿å­˜æœ€æ–°
        torch.save(checkpoint, self.output_dir / 'latest.pt')
        
        # ä¿å­˜æœ€ä½³
        if is_best:
            torch.save(checkpoint, self.output_dir / 'best.pt')
            print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: Dice = {dice:.4f}")
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        epochs = int(self.args['epochs'])
        patience = int(self.args.get('patience', 5))  # Early Stopping è€å¿ƒå€¼
        no_improve_count = 0
        
        print(f"\n{'='*50}")
        print(f"å¼€å§‹è®­ç»ƒ AutoSAM ({epochs} epochs)")
        print(f"Early Stopping: patience={patience}")
        print(f"{'='*50}\n")
        
        for epoch in range(1, epochs + 1):
            # è®­ç»ƒ
            train_loss, train_dice = self.train_epoch(epoch)
            
            # éªŒè¯
            val_dice = self.validate(epoch)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            self.scheduler.step()
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            is_best = val_dice > self.best_dice
            if is_best:
                self.best_dice = val_dice
                no_improve_count = 0  # é‡ç½®è®¡æ•°
            else:
                no_improve_count += 1
            
            self.save_checkpoint(epoch, val_dice, is_best)
            
            print(f"\nEpoch {epoch}/{epochs}:")
            print(f"  Train Loss: {train_loss:.4f}, Train Dice: {train_dice:.4f}")
            print(f"  Val Dice: {val_dice:.4f} {'(Best!)' if is_best else ''}")
            print(f"  LR: {self.scheduler.get_last_lr()[0]:.6f}")
            
            # Early Stopping æ£€æŸ¥
            if no_improve_count >= patience:
                print(f"\nâš ï¸ Early Stopping: Val Dice è¿ç»­ {patience} ä¸ª epoch æ²¡æœ‰æå‡")
                print(f"æœ€ä½³æ¨¡å‹å·²ä¿å­˜ (Dice: {self.best_dice:.4f})")
                break
        
        print(f"\nè®­ç»ƒå®Œæˆ! æœ€ä½³ Dice: {self.best_dice:.4f}")


def main():
    parser = argparse.ArgumentParser(description='AutoSAM 2D Training')
    
    # é…ç½®æ–‡ä»¶
    parser.add_argument('--config', '-c', type=str, default=None,
                        help='YAML é…ç½®æ–‡ä»¶è·¯å¾„')
    
    # è·¯å¾„å‚æ•°
    parser.add_argument('--dataset_path', type=str, 
                        default='./data/png_output',
                        help='æ•°æ®é›†è·¯å¾„')
    parser.add_argument('--output_dir', type=str, default='./output',
                        help='è¾“å‡ºç›®å½•')
    parser.add_argument('--sam_checkpoint', type=str,
                        default='./checkpoints/sam_vit_h.pth',
                        help='SAM æ£€æŸ¥ç‚¹è·¯å¾„')
    
    # æ¨¡å‹å‚æ•°
    parser.add_argument('--model_type', type=str, default='vit_h',
                        choices=['vit_h', 'vit_l', 'vit_b'],
                        help='SAM æ¨¡å‹ç±»å‹')
    parser.add_argument('--Idim', type=int, default=256,
                        help='ModelEmb è¾“å…¥å°ºå¯¸')
    parser.add_argument('--order', type=int, default=85,
                        help='HarDNet order')
    parser.add_argument('--depth_wise', type=bool, default=False,
                        help='ä½¿ç”¨ depth-wise å·ç§¯')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--epochs', type=int, default=50,
                        help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--batch_size', type=int, default=4,
                        help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--learning_rate', type=float, default=1e-3,
                        help='å­¦ä¹ ç‡')
    parser.add_argument('--weight_decay', type=float, default=1e-4,
                        help='æƒé‡è¡°å‡')
    parser.add_argument('--num_workers', type=int, default=4,
                        help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    
    args = parser.parse_args()
    
    # ä» YAML åŠ è½½é…ç½®
    if args.config:
        import yaml
        with open(args.config, 'r') as f:
            config = yaml.safe_load(f)
        
        # ç”¨ YAML é…ç½®è¦†ç›–é»˜è®¤å€¼
        for key, value in config.items():
            if hasattr(args, key):
                setattr(args, key, value)
    
    args = vars(args)
    
    # æ‰“å°é…ç½®
    print("\né…ç½®:")
    for k, v in args.items():
        if k != 'config':
            print(f"  {k}: {v}")
    print()
    
    # åˆ›å»ºè®­ç»ƒå™¨å¹¶å¼€å§‹è®­ç»ƒ
    trainer = AutoSAMTrainer(args)
    trainer.train()


if __name__ == '__main__':
    main()

